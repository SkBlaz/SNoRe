{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('SNoRe': conda)",
   "display_name": "Python 3.8.5 64-bit ('SNoRe': conda)",
   "metadata": {
    "interpreter": {
     "hash": "beac7c13dc476aacb47a8c3458104134843f9ea8d2ad6120dacbf3463c96f3d7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SNoRe Evaluation (Node Classification)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This notebook shows how to create the embedding of a network and use it to evaluate SNoRe-s performance in the node classification task.\n",
    "\n",
    "First we need to import some packages and method from them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from six import iteritems\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from snore import SNoRe, from_mat_file, TopKRanker"
   ]
  },
  {
   "source": [
    "Next we need to load the network, the labels and the multi label binarizer (We use sklearns MultiLabelBinarizer(range(num_classes))). Both the network and labels should be in scipy-s sparse format. We recommend saving the network to a .mat file similar to cora.mat and using our from_mat_file method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network, labels, mlb = from_mat_file(\"../data/cora.mat\")"
   ]
  },
  {
   "source": [
    "Next we need to create an embedding. The SNoRe class has 7 parameters:\n",
    "* fixed_dimension: If True, fixed number of features is used, otherwise space equivalent to |N|*dimension is used (SNoRe SDF),\n",
    "* dimension: number of features (fixed or space equivalent to |N|*dimension),\n",
    "* num_walks: number of random walks from each node,\n",
    "* max_walk_length: length of the longest random walk,\n",
    "* inclusion: inclusion threshold. Node needs to appear with frequency inclusion to appear in the hash representation,\n",
    "* metric: metric used for similarity calculation. If fixed_dimension==False, 'cosine', 'HPI', and 'HDI' are valid, otherwise 'cosine','HPI','HDI','euclidean', 'jaccard', 'seuclidean', and 'canberra' can be used,\n",
    "* num_bins: number of bins used in SNoRe SDF to digitize. The values are not digitized if None is chosen.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "05-Nov-20 19:44:48 - Generating and hashing random walks\n",
      "05-Nov-20 19:44:54 - Generating similarity matrix\n",
      "05-Nov-20 19:44:59 - Embedding done\n",
      "Embeding with shape (2708, 2708) created.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "fixed_dimension = False\n",
    "dimension = 256\n",
    "num_walks = 1024\n",
    "max_walk_length = 5\n",
    "inclusion = 0.005\n",
    "metric = \"cosine\"\n",
    "num_bins = 256\n",
    "\n",
    "# Embedding creation\n",
    "model = SNoRe(dimension=dimension, num_walks=num_walks, max_walk_length=max_walk_length, inclusion=inclusion,\n",
    "              fixed_dimension=fixed_dimension, metric=metric, num_bins=num_bins)\n",
    "emb = model.embed(network)\n",
    "print(\"Embeding with shape {} created.\".format(emb.shape))"
   ]
  },
  {
   "source": [
    "To evaluate the embedding we created, we will different percentages of randomly shuffled training data together with the logistic regression learner.\n",
    "\n",
    "You can customize this evaluation by changing the parameters num_shuffles (number of repetitions for each training percentage), all_percentages (If True percentages from 10-90 are used with increaments of 10, otherwise percentages data_perc are used), and data_perc (percentages of the training set if all_percentages parameter is False). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_shuffles = 10\n",
    "all_percentages = False\n",
    "data_perc = [0.5]\n",
    "\n",
    "# Evaluation\n",
    "all_results = defaultdict(list)\n",
    "shuffles = []\n",
    "for x in range(num_shuffles):\n",
    "    shuffles.append(skshuffle(emb, labels))\n",
    "if all_percentages:\n",
    "    training_percents = np.asarray(range(1, 10)) * .1\n",
    "else:\n",
    "    training_percents = data_perc\n",
    "\n",
    "for train_percent in training_percents:\n",
    "    for shuf in shuffles:\n",
    "        X, y = shuf\n",
    "\n",
    "        training_size = int(train_percent * X.shape[0])\n",
    "\n",
    "        X_train = X[:training_size, :]\n",
    "        y_train_ = y[:training_size]\n",
    "        y_train = [list() for x in range(y_train_.shape[0])]\n",
    "\n",
    "        cy = y_train_.tocoo()\n",
    "        for i, j in zip(cy.row, cy.col):\n",
    "            y_train[i].append(j)\n",
    "\n",
    "        assert sum(len(l) for l in y_train) == y_train_.nnz\n",
    "\n",
    "        X_test = X[training_size:, :]\n",
    "        y_test_ = y[training_size:]\n",
    "\n",
    "        y_test = [[] for _ in range(y_test_.shape[0])]\n",
    "\n",
    "        cy = y_test_.tocoo()\n",
    "        for i, j in zip(cy.row, cy.col):\n",
    "            y_test[i].append(j)\n",
    "\n",
    "        clf = TopKRanker(LogisticRegression())\n",
    "        clf.fit(X_train, y_train_)\n",
    "\n",
    "        # find out how many labels should be predicted\n",
    "        top_k_list = [len(l) for l in y_test]\n",
    "        preds = clf.predict(X_test, top_k_list)\n",
    "\n",
    "        results = {}\n",
    "        averages = [\"micro\", \"macro\"]\n",
    "        for average in averages:\n",
    "            results[average] = f1_score(mlb.fit_transform(y_test),\n",
    "                                        mlb.fit_transform(preds),\n",
    "                                        average=average)\n",
    "\n",
    "            all_results[train_percent].append(results)"
   ]
  },
  {
   "source": [
    "Lastly, let's print out the results we got from the evaluation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results of SNoRe using embeddings of dimensionality 2708\n-------------------\nTrain percent: 0.5\nAverage score: {'micro': 0.8469719350073854, 'macro': 0.8376325651518943}\n-------------------\n"
     ]
    }
   ],
   "source": [
    "print('Results of SNoRe using embeddings of dimensionality', emb.shape[1])\n",
    "print('-------------------')\n",
    "for train_percent in sorted(all_results.keys()):\n",
    "    print('Train percent:', train_percent)\n",
    "    avg_score = defaultdict(float)\n",
    "    for score_dict in all_results[train_percent]:\n",
    "        for metric, score in iteritems(score_dict):\n",
    "            avg_score[metric] += score\n",
    "    for metric in avg_score:\n",
    "        avg_score[metric] /= len(all_results[train_percent])\n",
    "    print('Average score:', dict(avg_score))\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}